{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bbf6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Random Forest\n",
    "\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset(\"tips\")\n",
    "df.head(2)\n",
    "\n",
    "# input features and target features\n",
    "X = df[['total_bill']] #,'tip','size']]  # x1, x2, x3 ...\n",
    "y = df['smoker']\n",
    "\n",
    "# encoding\n",
    "y = df['smoker'].map({'No':0,'Yes':1})\n",
    "\n",
    "# training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceee6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1cc1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelling Random forest classifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "clf_rf = RandomForestClassifier(\n",
    "    n_estimators = 100, # number of trees\n",
    "    random_state = 42,\n",
    "    max_depth = 3\n",
    ")\n",
    "clf_rf.fit(X_train,y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "\n",
    "# classification metrics\n",
    "cr_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db269b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c66f69",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da82b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dt = DecisionTreeClassifier(\n",
    "    max_depth = 3,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "clf_dt.fit(X_train,y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred_dt = clf_dt.predict(X_test)\n",
    "\n",
    "# classification metrics\n",
    "from sklearn.metrics import classification_report\n",
    "cr_dt = classification_report(y_test, y_pred_dt)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c37d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3e5ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a4cdf",
   "metadata": {},
   "source": [
    "## Bagging \n",
    "- Decision Trees Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1502b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "base_classifier = DecisionTreeClassifier()\n",
    "logistic_clf = LogisticRegression()\n",
    "\n",
    "bagging_classifier = BaggingClassifier(\n",
    "    clf_dt,\n",
    "    # base_classifier,\n",
    "    # logistic_clf, \n",
    "    n_estimators = 100, \n",
    "    random_state = 42,\n",
    "    )\n",
    "\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_bc = bagging_classifier.predict(X_test)\n",
    "cr_bc = classification_report(y_test, y_pred_bc)\n",
    "\n",
    "\n",
    "accuracy_bc = accuracy_score(y_test, y_pred_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b783e9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.94      0.77        31\n",
      "           1       0.60      0.17      0.26        18\n",
      "\n",
      "    accuracy                           0.65        49\n",
      "   macro avg       0.63      0.55      0.52        49\n",
      "weighted avg       0.64      0.65      0.59        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbb19b7",
   "metadata": {},
   "source": [
    "> ### Exercise\n",
    "- accuracies of: Random Forest, Bagging with Decision Trees (keep esimator number same, and random state same)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d74fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Random Forest 0.6530612244897959\n",
      "accuracy of Decision Tree 0.5714285714285714\n",
      "accuracy of Bagging Classifier 0.6530612244897959\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy of Random Forest\", accuracy_rf)\n",
    "print(\"accuracy of Decision Tree\", accuracy_dt)\n",
    "print(\"accuracy of Bagging Classifier\", accuracy_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853deafc",
   "metadata": {},
   "source": [
    "> ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e37bf57",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "- With AdaBoost and XG Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f53d6c",
   "metadata": {},
   "source": [
    "### **AdaBoost** \n",
    "\n",
    "- â†’ focuses on misclassified samples by adjusting weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cb279db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "adaboost_classifier = AdaBoostClassifier(\n",
    "    base_classifier, \n",
    "    n_estimators=50, \n",
    "    random_state=42,\n",
    "\n",
    "    learning_rate = 1.0, # in boosting\n",
    "\n",
    ")\n",
    "adaboost_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_ac = adaboost_classifier.predict(X_test)\n",
    "\n",
    "cr_ac = classification_report(y_test, y_pred_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa28dc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.90      0.76        31\n",
      "           1       0.50      0.17      0.25        18\n",
      "\n",
      "    accuracy                           0.63        49\n",
      "   macro avg       0.58      0.53      0.50        49\n",
      "weighted avg       0.60      0.63      0.57        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5574e717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f26bd97",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "065a4239",
   "metadata": {},
   "source": [
    "## XG Boost\n",
    "- Extreme Gradient Boost \n",
    "-  more advanced, with optimizations like regularization and parallelization for speed and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a8e43bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42b4892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c37c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = XGBClassifier(\n",
    "    n_estimators=100, \n",
    "    learning_rate=0.1, \n",
    "    max_depth=3, \n",
    "    random_state=42\n",
    ")\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = bagging_classifier.predict(X_test)\n",
    "cr_xgb = classification_report(y_test, y_pred_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6215fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.94      0.77        31\n",
      "           1       0.60      0.17      0.26        18\n",
      "\n",
      "    accuracy                           0.65        49\n",
      "   macro avg       0.63      0.55      0.52        49\n",
      "weighted avg       0.64      0.65      0.59        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8164fb2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df4db39d",
   "metadata": {},
   "source": [
    "## ---**OPTIONAL** ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29016c",
   "metadata": {},
   "source": [
    "### **Regularization**\n",
    "- Prevents a model from becoming too complex, and memorizing the training data\n",
    "- also called OVERFITTING\n",
    "- it kind of adds a penalty to the model if it uses too complex models\n",
    "\n",
    "- \n",
    "\n",
    "- Two Types:\n",
    "    - Lasso - L1 Regularization - Absolute values of coefficients - Some become exactly zero\n",
    "    - Ridge - L 2 Regularization  - Squaring values of coefficients - Shrinks but keeps all, never makes any zero\n",
    "    - Use Ridge when you want to keep all features but control their influence.\n",
    "    - Use Lasso when you want the model to automatically drop irrelevant features.\n",
    "\n",
    "\n",
    "> #### Lasso Regularization: \n",
    "```py\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "ridge = Ridge(alpha=1.0)  # alpha controls penalty strength\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "print(\"Ridge coefficients:\", ridge.coef_)\n",
    "print(\"Ridge score:\", ridge.score(X_test, y_test))\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "> #### Ridge Regularization: \n",
    "\n",
    "```py\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lasso = Lasso(alpha=0.1)  # smaller alpha = less penalty\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "print(\"Lasso coefficients:\", lasso.coef_)\n",
    "print(\"Lasso score:\", lasso.score(X_test, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526fd52b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8db13ae8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "750cb6c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b85fd6a",
   "metadata": {},
   "source": [
    "> #### **Pruning**\n",
    "- Simplifying decision trees\n",
    "- cut off the parts that are too detailed and only fit the noise in the data\n",
    "- remove branches that do no improve predictions\n",
    "```python\n",
    "model = DecisionTreeClassifier(max_depth=3) # limits depth = pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72591364",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
